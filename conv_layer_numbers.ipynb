{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "color_channels = 1  # data is in black and white, 1 channel\n",
    "image_height = 28\n",
    "image_width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # sets up the data from mnist\n",
    "\n",
    "# print(x_train.shape)  # contains 60,000 imgs that are 28x28\n",
    "# print(y_train.shape)  # 60,000 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Setting up Neural Network\n",
    "class CNN:\n",
    "    def __init__(self, image_height, image_width, channels, num_classes):\n",
    "        self.input_layer = tf.placeholder(dtype=tf.float32, shape=[None, image_height, image_width, channels])\n",
    "        \n",
    "        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters=32, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)  # convolutional layer\n",
    "        \"\"\"The first input is the layer before the current one, the last input\n",
    "            is the activation function. This act fn helps neural net solve for what\n",
    "            the object could potentially be.\"\"\"\n",
    "        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[2, 2], strides=2)  # pooling layer\n",
    "        \n",
    "        conv_layer_2 = tf.layers.conv2d(pooling_layer_1, filters=32, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)  # convolutional layer\n",
    "        pooling_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=[2, 2], strides=2)  # pooling layer\n",
    "        \n",
    "        # create the flatten layer...\n",
    "        flattened_pooling = tf.layers.flatten(pooling_layer_2)  # pooling layer\n",
    "        dense_layer = tf.layers.dense(flattened_pooling, 1024, activation=tf.nn.relu)  # dense layer: takes last layer, number of neurons to activate activation layer, and activation fn\n",
    "        \n",
    "        dropout = tf.layers.dropout(dense_layer, rate=0.4, training=True)  # dropout layer\n",
    "        outputs = tf.layers.dense(dropout, num_classes)  # output layer\n",
    "        \n",
    "        \n",
    "        # Getting data from the network\n",
    "        self.choice = tf.argmax(outputs, axis=1)  # (1) CHOICE VARIABLE \n",
    "            # axis is dependent on which var to check for maximum, output is 1d, theres 1 axis\n",
    "        self.probability = tf.nn.softmax(outputs)  # (2) SCALE PROBABILITIES\n",
    "        self.labels = tf.placeholder(dtype=tf.float32, name=\"labels\")  # (3) CREATE LABELS CONTAINER\n",
    "        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice)  # (4) GATHERING ACCURACY\n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)  # (5) ONE-HOT ENCODING, depth determined on num of possibilities (10)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=outputs)  # (6) LOSS FN\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3)  # (7) OPTIMIZER, helps reduce loss with LEARNING RATE var (0>x>1)\n",
    "        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step())  # (8) TRAINING STEP\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0706 19:31:29.566580 4474418624 deprecation.py:323] From <ipython-input-5-2120cb5d6545>:6: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0706 19:31:29.571243 4474418624 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0706 19:31:29.750252 4474418624 deprecation.py:323] From <ipython-input-5-2120cb5d6545>:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0706 19:31:29.868784 4474418624 deprecation.py:323] From <ipython-input-5-2120cb5d6545>:16: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0706 19:31:30.046494 4474418624 deprecation.py:323] From <ipython-input-5-2120cb5d6545>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0706 19:31:30.272991 4474418624 deprecation.py:323] From <ipython-input-5-2120cb5d6545>:19: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0706 19:31:30.384108 4474418624 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "steps = 5000\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "\n",
    "test_img = x_test[2]\n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "test_img = test_img.reshape(-1, image_height, image_width, 1)\n",
    "\n",
    "x_train = x_train.reshape(-1, image_height, image_width, 1)\n",
    "\n",
    "cnn = CNN(image_height, image_width, color_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 0.15625)\n",
      "(None, 0.09375)\n",
      "(None, 0.17708333)\n",
      "(None, 0.1640625)\n",
      "(None, 0.18125)\n",
      "(None, 0.19791667)\n",
      "(None, 0.20982143)\n",
      "(None, 0.22265625)\n",
      "(None, 0.22569445)\n",
      "(None, 0.25)\n",
      "(None, 0.26136363)\n",
      "(None, 0.28385416)\n",
      "(None, 0.29807693)\n",
      "(None, 0.3125)\n",
      "(None, 0.32083333)\n",
      "(None, 0.31640625)\n",
      "(None, 0.3180147)\n",
      "(None, 0.3246528)\n",
      "(None, 0.3256579)\n",
      "(None, 0.3234375)\n",
      "(None, 0.32440478)\n",
      "(None, 0.3309659)\n",
      "(None, 0.33831522)\n",
      "(None, 0.3372396)\n",
      "(None, 0.34125)\n",
      "(None, 0.35216346)\n",
      "(None, 0.35416666)\n",
      "(None, 0.3627232)\n",
      "(None, 0.36422414)\n",
      "(None, 0.36666667)\n",
      "(None, 0.37298387)\n",
      "(None, 0.37304688)\n",
      "(None, 0.37405303)\n",
      "(None, 0.37775734)\n",
      "(None, 0.38035715)\n",
      "(None, 0.3793403)\n",
      "(None, 0.38175675)\n",
      "(None, 0.38651314)\n",
      "(None, 0.3878205)\n",
      "(None, 0.38828126)\n",
      "(None, 0.3910061)\n",
      "(None, 0.39285713)\n",
      "(None, 0.3946221)\n",
      "(None, 0.39772728)\n",
      "(None, 0.4)\n",
      "(None, 0.40625)\n",
      "(None, 0.41156915)\n",
      "(None, 0.41731772)\n",
      "(None, 0.42091838)\n",
      "(None, 0.42375)\n",
      "(None, 0.4283088)\n",
      "(None, 0.43389422)\n",
      "(None, 0.4369104)\n",
      "(None, 0.44502315)\n",
      "(None, 0.44829544)\n",
      "(None, 0.45256695)\n",
      "(None, 0.45339912)\n",
      "(None, 0.45797414)\n",
      "(None, 0.4618644)\n",
      "(None, 0.46510416)\n",
      "(None, 0.4692623)\n",
      "(None, 0.47227824)\n",
      "(None, 0.47420636)\n",
      "(None, 0.47558594)\n",
      "(None, 0.47740385)\n",
      "(None, 0.48058712)\n",
      "(None, 0.48367536)\n",
      "(None, 0.48759192)\n",
      "(None, 0.49139494)\n",
      "(None, 0.4955357)\n",
      "(None, 0.49823943)\n",
      "(None, 0.50130206)\n",
      "(None, 0.5042808)\n",
      "(None, 0.5059122)\n",
      "(None, 0.5075)\n",
      "(None, 0.50863487)\n",
      "(None, 0.50933444)\n",
      "(None, 0.50961536)\n",
      "(None, 0.511076)\n",
      "(None, 0.51171875)\n",
      "(None, 0.5150463)\n",
      "(None, 0.515625)\n",
      "(None, 0.51844877)\n",
      "(None, 0.5204613)\n",
      "(None, 0.5224265)\n",
      "(None, 0.5221657)\n",
      "(None, 0.5237069)\n",
      "(None, 0.5255682)\n",
      "(None, 0.5266854)\n",
      "(None, 0.5298611)\n",
      "(None, 0.5319368)\n",
      "(None, 0.5339674)\n",
      "(None, 0.5369624)\n",
      "(None, 0.5398936)\n",
      "(None, 0.5398026)\n",
      "(None, 0.5416667)\n",
      "(None, 0.54349226)\n",
      "(None, 0.54591835)\n",
      "(None, 0.5473485)\n",
      "(None, 0.54875)\n",
      "(None, 0.55043316)\n",
      "(None, 0.5514706)\n",
      "(None, 0.55248785)\n",
      "(None, 0.55408657)\n",
      "(None, 0.55654764)\n",
      "(None, 0.5568986)\n",
      "(None, 0.55928737)\n",
      "(None, 0.5613426)\n",
      "(None, 0.5625)\n",
      "(None, 0.56363636)\n",
      "(None, 0.5647523)\n",
      "(None, 0.56668526)\n",
      "(None, 0.5688606)\n",
      "(None, 0.57127196)\n",
      "(None, 0.57336956)\n",
      "(None, 0.57543105)\n",
      "(None, 0.57772434)\n",
      "(None, 0.57865465)\n",
      "(None, 0.58035713)\n",
      "(None, 0.5809896)\n",
      "(None, 0.5829029)\n",
      "(None, 0.58478487)\n",
      "(None, 0.58536583)\n",
      "(None, 0.5866935)\n",
      "(None, 0.58675)\n",
      "(None, 0.5875496)\n",
      "(None, 0.5885827)\n",
      "(None, 0.5895996)\n",
      "(None, 0.59132755)\n",
      "(None, 0.5923077)\n",
      "(None, 0.5930343)\n",
      "(None, 0.5949337)\n",
      "(None, 0.5972744)\n",
      "(None, 0.59724814)\n",
      "(None, 0.5986111)\n",
      "(None, 0.6004136)\n",
      "(None, 0.60173357)\n",
      "(None, 0.6034873)\n",
      "(None, 0.60454136)\n",
      "(None, 0.60513395)\n",
      "(None, 0.6057181)\n",
      "(None, 0.6071743)\n",
      "(None, 0.6097028)\n",
      "(None, 0.61067706)\n",
      "(None, 0.61206895)\n",
      "(None, 0.6130137)\n",
      "(None, 0.6128827)\n",
      "(None, 0.6123311)\n",
      "(None, 0.613255)\n",
      "(None, 0.6152083)\n",
      "(None, 0.615894)\n",
      "(None, 0.61636513)\n",
      "(None, 0.61764705)\n",
      "(None, 0.61891234)\n",
      "(None, 0.6195564)\n",
      "(None, 0.6211939)\n",
      "(None, 0.62221336)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        print(sess.run((cnn.train_operation, cnn.accuracy_op),\n",
    "                       feed_dict={cnn.input_layer:x_train[step: step + batch_size],\n",
    "                                cnn.labels:y_train[step: step + batch_size]}))\n",
    "        step += batch_size\n",
    "    \n",
    "    print(sess.run(cnn.choice, feed_dict={cnn.input_layer:test_img}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
